{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71e00c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import opensmile\n",
    "import IPython\n",
    "import os\n",
    "import librosa\n",
    "import glob\n",
    "import parselmouth \n",
    "import statistics\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from parselmouth.praat import call\n",
    "from scipy.stats.mstats import zscore\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56cdc3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function to measure source acoustics using default male parameters.\n",
    "\n",
    "def measurePitch(voiceID, f0min, f0max, unit):\n",
    "    pitch_grad_three_list = []\n",
    "    pitch_range_three_list = []\n",
    "    \n",
    "    sound = parselmouth.Sound(voiceID) # read the sound\n",
    "    duration = call(sound, \"Get total duration\") # duration\n",
    "    pitch = call(sound, \"To Pitch (cc)\", 0, f0min, 15, 'no', 0.03, 0.45, -0.29, 3.5, 0.14, f0max)\n",
    "    meanF0 = call(pitch, \"Get mean\", 0, 0, unit) # get mean pitch\n",
    "    minF0 = call(pitch, \"Get minimum\", 0, 0, unit, \"parabolic\") # get mean pitch\n",
    "    maxF0 = call(pitch, \"Get maximum\", 0, 0, unit, \"parabolic\") # get mean pitch\n",
    "    stdevF0 = call(pitch, \"Get standard deviation\", 0 ,0, unit) # get standard deviation\n",
    "    harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, f0min, 0.1, 1.0)\n",
    "    hnr = call(harmonicity, \"Get mean\", 0, 0)\n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", f0min, f0max)\n",
    "    localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    rapJitter = call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ppq5Jitter = call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ddpJitter = call(pointProcess, \"Get jitter (ddp)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localShimmer =  call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    localdbShimmer = call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq3Shimmer = call([sound, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    aqpq5Shimmer = call([sound, pointProcess], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq11Shimmer =  call([sound, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    ddaShimmer = call([sound, pointProcess], \"Get shimmer (dda)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    \n",
    "    \n",
    "    time_steps = 0.033\n",
    "    pitch_values = pitch.selected_array['frequency']\n",
    "    pitch_values = pitch_values[pitch_values != 0]\n",
    "    \n",
    "    time_step_buff_upper = 15\n",
    "    time_step_buff_low = 15\n",
    "    next_count = 0\n",
    "    mean_count=0\n",
    "    for i in range(len(pitch_values)):\n",
    "        pitches_upper = np.absolute(pitch_values[i:(i+time_step_buff_upper)])\n",
    "        if i >= time_step_buff_low:\n",
    "            pitches_lower = np.absolute(pitch_values[(i-time_step_buff_low):(i)])\n",
    "        if i< time_step_buff_low:\n",
    "            pitches_lower = np.absolute(pitch_values[0:i])\n",
    "\n",
    "        median_buffer = np.median(pitch_values)\n",
    "        window_median = np.median(np.concatenate([pitches_lower, pitches_upper]))\n",
    "\n",
    "        if i == 0:\n",
    "            #print(\"first element was: \" + str(pitch_values[i]))\n",
    "            if pitch_values[i] <= median_buffer-.4*median_buffer:\n",
    "                pitch_values[i] = pitch_values[i]*2\n",
    "\n",
    "            if pitch_values[i] >= median_buffer+.8*median_buffer:\n",
    "                pitch_values[i] = pitch_values[i]/2\n",
    "            #print(\"and is now: \" +str(pitch_values[i]))\n",
    "\n",
    "        if pitch_values[i] <= window_median-0.4*window_median and pitch_values[i]*2 < 300:\n",
    "            pitch_values[i] = pitch_values[i]*2\n",
    "            #print(\"Drop detected now: \" +str(pitch_values[i])+ \" at count: \" + str(i))\n",
    "        if pitch_values[i] >= window_median+0.8*window_median and pitch_values[i]/2 > 75:\n",
    "            pitch_values[i] = pitch_values[i]/2\n",
    "            #print(\"Increase detected now: \" +str(pitch_values[i])+ \" at count: \" + str(i))\n",
    "  \n",
    "    \n",
    "    \n",
    "    last_avg = statistics.mean(pitch_values[0:(3)])\n",
    "    i = 3\n",
    "    \n",
    "    for count in range(math.ceil(len(pitch_values)/3)-1):\n",
    "            avg_for_range_cal = statistics.mean(np.absolute(pitch_values[i:(i+3)]))\n",
    "            pitch_range_three_list.append(np.absolute(avg_for_range_cal-last_avg))\n",
    "            pitch_grad_three_list.append(np.absolute(avg_for_range_cal-last_avg)/(len(pitch_values[i:i+3]+3)*0.033))\n",
    "            last_avg = avg_for_range_cal        \n",
    "            i = i + 3\n",
    "  \n",
    "    F0_dev_step_mean = statistics.mean(pitch_range_three_list)\n",
    "    F0_dev_step_max = max(pitch_range_three_list)\n",
    "    \n",
    "    relative_pitch_grad_to_mean = np.asarray(pitch_grad_three_list)/meanF0\n",
    "    relative_pitch_grad_m_mean_d_sd =  (np.asarray(pitch_grad_three_list)-meanF0)/stdevF0\n",
    "     \n",
    "    relative_pitch_range_to_mean = np.asarray(pitch_range_three_list)/meanF0\n",
    "    relative_pitch_range_m_mean_d_sd =  (np.asarray(pitch_range_three_list)-meanF0)/stdevF0\n",
    "\n",
    "    max_rel_F0range_d_mean = max(relative_pitch_range_to_mean)\n",
    "    min_rel_F0range_d_mean = min(relative_pitch_range_to_mean)\n",
    "    sd_rel_F0range_d_mean = statistics.pstdev(relative_pitch_range_to_mean)\n",
    "    mean_rel_F0range_d_mean = statistics.mean(relative_pitch_range_to_mean)\n",
    "        \n",
    "    max_rel_F0range_m_mean_d_sd = max(relative_pitch_range_m_mean_d_sd)\n",
    "    min_rel_F0range_m_mean_d_sd = min(relative_pitch_range_m_mean_d_sd)\n",
    "    sd_rel_F0range_m_mean_d_sd = statistics.pstdev(relative_pitch_range_m_mean_d_sd)\n",
    "    mean_rel_F0range_m_mean_d_sd = statistics.mean(relative_pitch_range_m_mean_d_sd)\n",
    "       \n",
    "    max_rel_F0grad_d_mean = max(relative_pitch_grad_to_mean)\n",
    "    min_rel_F0grad_d_mean = min(relative_pitch_grad_to_mean)\n",
    "    sd_rel_F0grad_d_mean = statistics.pstdev(relative_pitch_grad_to_mean)\n",
    "    mean_rel_F0grad_d_mean = statistics.mean(relative_pitch_grad_to_mean)\n",
    "        \n",
    "    max_rel_F0grad_m_mean_d_sd = max(relative_pitch_grad_m_mean_d_sd)\n",
    "    min_rel_F0grad_m_mean_d_sd = min(relative_pitch_grad_m_mean_d_sd)\n",
    "    sd_rel_F0grad_m_mean_d_sd = statistics.pstdev(relative_pitch_grad_m_mean_d_sd)\n",
    "    mean_rel_F0grad_m_mean_d_sd = statistics.mean(relative_pitch_grad_m_mean_d_sd)\n",
    "                       \n",
    "    #print(pitch)\n",
    "    #print(pitch_values)\n",
    "    #print(hnr)\n",
    "    #print(localJitter)\n",
    "    #print(localabsoluteJitter)\n",
    "    #print(localShimmer)\n",
    "    #print(apq3Shimmer)\n",
    "\n",
    "    \n",
    "    return duration, meanF0, minF0, maxF0, stdevF0, hnr, localJitter, localabsoluteJitter, rapJitter, ppq5Jitter, ddpJitter, localShimmer, localdbShimmer, apq3Shimmer, aqpq5Shimmer, apq11Shimmer, ddaShimmer, max_rel_F0grad_d_mean, min_rel_F0grad_d_mean, sd_rel_F0grad_d_mean,mean_rel_F0grad_d_mean, max_rel_F0grad_m_mean_d_sd, min_rel_F0grad_m_mean_d_sd, sd_rel_F0grad_m_mean_d_sd, mean_rel_F0grad_m_mean_d_sd, max_rel_F0range_d_mean, min_rel_F0range_d_mean, sd_rel_F0range_d_mean, mean_rel_F0range_d_mean, max_rel_F0range_m_mean_d_sd, min_rel_F0range_m_mean_d_sd, sd_rel_F0range_m_mean_d_sd, mean_rel_F0range_m_mean_d_sd, F0_dev_step_mean, F0_dev_step_max  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d75d03",
   "metadata": {},
   "source": [
    "pitch_values = np.copy(pitch_values_in)\n",
    "time_step_buff_upper = 20\n",
    "time_step_buff_low = 20\n",
    "next_count = 0\n",
    "mean_count=0\n",
    "for i in range(len(pitch_values)):\n",
    "    pitches_upper = np.absolute(pitch_values[i:(i+time_step_buff_upper)])\n",
    "    if i >= time_step_buff_low:\n",
    "        pitches_lower = np.absolute(pitch_values[(i-time_step_buff_low):(i)])\n",
    "    if i< time_step_buff_low:\n",
    "        pitches_lower = np.absolute(pitch_values[0:i])\n",
    "\n",
    "    median_buffer = np.median(pitch_values)\n",
    "    window_median = np.median(np.concatenate([pitches_lower, pitches_upper]))\n",
    "    \n",
    "    if i == 0:\n",
    "        print(\"first element was: \" + str(pitch_values[i]))\n",
    "        if pitch_values[i] <= median_buffer-.4*median_buffer:\n",
    "            pitch_values[i] = pitch_values[i]*2\n",
    "            \n",
    "        if pitch_values[i] >= median_buffer+.8*median_buffer:\n",
    "            pitch_values[i] = pitch_values[i]/2\n",
    "        print(\"and is now: \" +str(pitch_values[i]))\n",
    "        \n",
    "    if pitch_values[i] <= window_median-0.4*window_median and pitch_values[i]*2 < 300:\n",
    "        pitch_values[i] = pitch_values[i]*2\n",
    "        print(\"Drop detected now: \" +str(pitch_values[i])+ \" at count: \" + str(i))\n",
    "    if pitch_values[i] >= window_median+0.8*window_median and pitch_values[i]/2 > 75:\n",
    "        pitch_values[i] = pitch_values[i]/2\n",
    "        print(\"Increase detected now: \" +str(pitch_values[i])+ \" at count: \" + str(i))\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a04596",
   "metadata": {},
   "source": [
    "count1=0\n",
    "count2=0\n",
    "dcount3=0\n",
    "count4=0\n",
    "count5=0\n",
    "count6 = 0\n",
    "\n",
    "for i in range(len(pitch_values)):\n",
    "\n",
    "    if pitch_values[i] <75 and pitch_values[i] >= 74.935:\n",
    "        count1 = count1+1\n",
    "    if pitch_values[i] >=75 and pitch_values[i] <150:\n",
    "        count2 = count2+1\n",
    "    if pitch_values[i] >=150 and pitch_values[i] <200:\n",
    "        count3 = count3+1\n",
    "    if pitch_values[i] >=200 and pitch_values[i] <250:\n",
    "        count4 = count4+1\n",
    "    if pitch_values[i] >=250 and pitch_values[i] <=300:\n",
    "        count5 = count5+1\n",
    "    if pitch_values[i] >300:\n",
    "        count6 = count6+1\n",
    "\n",
    "\n",
    "\n",
    "print(count1)\n",
    "print(count2)\n",
    "print(count3)\n",
    "print(count4)\n",
    "print(count5)\n",
    "print(count6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c63e14",
   "metadata": {},
   "source": [
    "median_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa94ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39d26812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_centoid(wave_file, meanF0, stdevF0):\n",
    "        data, sample_rate = librosa.load(wave_file)\n",
    "        spectrum_Cen = librosa.feature.spectral_centroid(y = data, sr=sample_rate, S=None, n_fft=2048, hop_length=512, \n",
    "                                      freq=None, win_length=1024, window='hann', center=True, \n",
    "                                      pad_mode='constant')\n",
    "    \n",
    "        spec_cen_list = (spectrum_Cen[0])\n",
    "        spec_cen_list_grouped = []\n",
    "        #print(spec_cen_list)\n",
    "        \n",
    "        last_avg = statistics.mean(spec_cen_list[0:(3)])\n",
    "        i = 3\n",
    "        \n",
    "        for count in range(math.ceil(len(spec_cen_list)/3)-1):\n",
    "                avg_for_range = statistics.mean(np.absolute(spec_cen_list[i:(i+3)]))\n",
    "                spec_cen_list_grouped.append(np.absolute(avg_for_range-last_avg))\n",
    "                last_avg = avg_for_range        \n",
    "                i = i + 3\n",
    "\n",
    "        \n",
    "        \n",
    "        relative_spec_cen_to_mean = np.asarray(spec_cen_list_grouped)/meanF0\n",
    "        relative_spec_cen_m_mean_d_sd =  (np.asarray(spec_cen_list_grouped)-meanF0)/stdevF0\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        spec_cen_relF0_mean_mean =statistics.mean(relative_spec_cen_to_mean)\n",
    "        spec_cen_relF0_mean_sd = statistics.pstdev(relative_spec_cen_to_mean)\n",
    "        spec_cen_relF0_mean_median = statistics.median(relative_spec_cen_to_mean)\n",
    "        \n",
    "        spec_cen_m_mean_d_sd_mean =statistics.mean(relative_spec_cen_m_mean_d_sd)\n",
    "        spec_cen_m_mean_d_sd_sd = statistics.pstdev(relative_spec_cen_m_mean_d_sd)\n",
    "        spec_cen_m_mean_d_sd_median = statistics.median(relative_spec_cen_m_mean_d_sd)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return spec_cen_relF0_mean_mean, spec_cen_relF0_mean_sd, spec_cen_relF0_mean_median, spec_cen_m_mean_d_sd_mean, spec_cen_m_mean_d_sd_sd, spec_cen_m_mean_d_sd_median\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e83b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ad0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function measures formants using Formant Position formula\n",
    "def measureFormants(sound, wave_file, f0min,f0max):\n",
    "    sound = parselmouth.Sound(sound) # read the sound\n",
    "    pitch = call(sound, \"To Pitch (cc)\", 0, f0min, 15, 'no', 0.03, 0.45, 0.01, 0.35, 0.14, f0max)\n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", f0min, f0max)\n",
    "    \n",
    "    formants = call(sound, \"To Formant (burg)\", 0.0025, 5, 5000, 0.025, 50)\n",
    "    numPoints = call(pointProcess, \"Get number of points\")\n",
    "\n",
    "    f1_list = []\n",
    "    f2_list = []\n",
    "    f3_list = []\n",
    "    f4_list = []\n",
    "    \n",
    "    # Measure formants only at glottal pulses\n",
    "    for point in range(0, numPoints):\n",
    "        point += 1\n",
    "        t = call(pointProcess, \"Get time from index\", point)\n",
    "        f1 = call(formants, \"Get value at time\", 1, t, 'Hertz', 'Linear')\n",
    "        f2 = call(formants, \"Get value at time\", 2, t, 'Hertz', 'Linear')\n",
    "        f3 = call(formants, \"Get value at time\", 3, t, 'Hertz', 'Linear')\n",
    "        f4 = call(formants, \"Get value at time\", 4, t, 'Hertz', 'Linear')\n",
    "        f1_list.append(f1)\n",
    "        f2_list.append(f2)\n",
    "        f3_list.append(f3)\n",
    "        f4_list.append(f4)\n",
    "    \n",
    "    f1_list = [f1 for f1 in f1_list if str(f1) != 'nan']\n",
    "    f2_list = [f2 for f2 in f2_list if str(f2) != 'nan']\n",
    "    f3_list = [f3 for f3 in f3_list if str(f3) != 'nan']\n",
    "    f4_list = [f4 for f4 in f4_list if str(f4) != 'nan']\n",
    "    \n",
    "    # calculate mean formants across pulses\n",
    "    f1_mean = statistics.mean(f1_list)\n",
    "    f2_mean = statistics.mean(f2_list)\n",
    "    f3_mean = statistics.mean(f3_list)\n",
    "    f4_mean = statistics.mean(f4_list)\n",
    "    \n",
    "    # calculate median formants across pulses, this is what is used in all subsequent calcualtions\n",
    "    # you can use mean if you want, just edit the code in the boxes below to replace median with mean\n",
    "    f1_median = statistics.median(f1_list)\n",
    "    #print(f1_list)\n",
    "    f2_median = statistics.median(f2_list)\n",
    "    f3_median = statistics.median(f3_list)\n",
    "    f4_median = statistics.median(f4_list)\n",
    "    f1_sd = statistics.pstdev(f1_list)\n",
    "    f2_sd = statistics.pstdev(f2_list)\n",
    "    f3_sd = statistics.pstdev(f3_list)\n",
    "    f4_sd = statistics.pstdev(f4_list)\n",
    "\n",
    "    \n",
    "    return f1_mean, f2_mean, f3_mean, f4_mean, f1_median, f2_median, f3_median, f4_median, f1_sd, f2_sd, f3_sd, f4_sd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb205048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "043e8b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runPCA(df):\n",
    "    # z-score the Jitter and Shimmer measurements\n",
    "    measures = ['localJitter', 'localabsoluteJitter', 'rapJitter', 'ppq5Jitter', 'ddpJitter',\n",
    "                'localShimmer', 'localdbShimmer', 'apq3Shimmer', 'apq5Shimmer', 'apq11Shimmer', 'ddaShimmer']\n",
    "    x = df.loc[:, measures].values\n",
    "    x = StandardScaler().fit_transform(x)\n",
    "    # PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    principalComponents = pca.fit_transform(x)\n",
    "    principalDf = pd.DataFrame(data = principalComponents, columns = ['JitterPCA', 'ShimmerPCA'])\n",
    "    principalDf\n",
    "    return principalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc7238e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demoTableCreate():\n",
    "    demographic_files = [\"train_split_Depression_AVEC2017.csv\", \"dev_split_Depression_AVEC2017.csv\", \"full_test_split.csv\"]\n",
    "    dataDemographic = pd.DataFrame()\n",
    "    for k in range(len(demographic_files)):\n",
    "\n",
    "        dataDemographic_temp = pd.read_csv(\"C:/Users/admul/Desktop/School/Thesis/DAICWOZ Data/\" + demographic_files[k] , usecols=[\"Participant_ID\",\"PHQ8_Binary\",\"PHQ8_Score\",\"Gender\"], skip_blank_lines=True, na_filter=True).dropna()\n",
    "\n",
    "        if k == 0:\n",
    "            dataDemographic_temp[\"data_set\"] = \"0\"\n",
    "        if k == 1:\n",
    "            dataDemographic_temp[\"data_set\"] = \"1\"\n",
    "        if k == 2:\n",
    "            dataDemographic_temp[\"data_set\"] = \"2\"\n",
    "    \n",
    "        dataDemographic = dataDemographic.append(dataDemographic_temp)\n",
    "        \n",
    "    del dataDemographic_temp\n",
    "    return dataDemographic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d8b6331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demographicInfo(patient_id):\n",
    "    PHQ8_Binary =  dataDemographic['PHQ8_Binary'].loc[dataDemographic['Participant_ID'] == float(patient_id)]\n",
    "    PHQ8_Binary1 = PHQ8_Binary.iat[0]\n",
    "    PHQ8_Score = dataDemographic['PHQ8_Score'].loc[dataDemographic['Participant_ID'] == float(patient_id)]\n",
    "    PHQ8_Score1 = PHQ8_Score.iat[0]\n",
    "    Gender = dataDemographic['Gender'].loc[dataDemographic['Participant_ID'] == float(patient_id)]\n",
    "    Gender1 = Gender.iat[0]\n",
    "    Data_set = dataDemographic['data_set'].loc[dataDemographic['Participant_ID'] == float(patient_id)]\n",
    "    Data_set1 = Data_set.iat[0]\n",
    "    \n",
    "    return Data_set1, PHQ8_Binary1, PHQ8_Score1, Gender1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87f2f6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def COVAREP(patient_id):\n",
    "    \n",
    "    dataCOVAREP= pd.read_csv( \"C:/insert directory\" + patient_id +\".csv\",\n",
    "                             sep=',',header=None)\n",
    "    dataCOVAREP.columns =['F0', 'VoiceMarker', 'NAQ', 'QoQ', 'H1H2', 'PSP', 'MDQ', 'peakSlope', 'RdShape','Rd_Conf',\n",
    "                         'Creak','MCEP_0','MCEP_1','MCEP_2','MCEP_3','MCEP_4','MCEP_5','MCEP_6','MCEP_7','MCEP_8',\n",
    "                         'MCEP_9','MCEP_10','MCEP_11','MCEP_12','MCEP_13','MCEP_14','MCEP_15','MCEP_16','MCEP_17','MCEP_18',\n",
    "                         'MCEP_19','MCEP_20','MCEP_21','MCEP_22','MCEP_23','MCEP_24','HMPDM_0','HMPDM_1','HMPDM_2','HMPDM_3',\n",
    "                         'HMPDM_4','HMPDM_5','HMPDM_6','HMPDM_7','HMPDM_8','HMPDM_9','HMPDM_10','HMPDM_11','HMPDM_12','HMPDM_13',\n",
    "                         'HMPDM_14','HMPDM_15','HMPDM_16','HMPDM_17','HMPDM_18','HMPDM_19','HMPDM_20','HMPDM_21','HMPDM_22','HMPDM_23',\n",
    "                         'HMPDM_24','HMPDD_0','HMPDD_1','HMPDD_2','HMPDD_3','HMPDD_4','HMPDD_5','HMPDD_6','HMPDD_7','HMPDD_8',\n",
    "                          'HMPDD_9','HMPDD_10','HMPDD_11', 'HMPDD_12']\n",
    "\n",
    "\n",
    "    dataCOVAREP_Voiced = dataCOVAREP.loc[dataCOVAREP['VoiceMarker'] == 1]\n",
    "    resultsC = pd.DataFrame(index=np.arange(1), columns=np.arange(1))\n",
    "\n",
    "    resultsC['patient_id'] = float(patient_id)\n",
    "    resultsC['F0_C_mean'] = statistics.mean(dataCOVAREP_Voiced['F0'])\n",
    "    resultsC['NAQ_mean'] = statistics.mean(dataCOVAREP_Voiced['NAQ'])\n",
    "    resultsC['QoQ_mean'] = statistics.mean(dataCOVAREP_Voiced['QoQ'])\n",
    "    resultsC['H1H2_mean'] = statistics.mean(dataCOVAREP_Voiced['H1H2'])\n",
    "    resultsC['PSP_mean'] = statistics.mean(dataCOVAREP_Voiced['PSP'])\n",
    "    resultsC['MDQ_mean'] = statistics.mean(dataCOVAREP_Voiced['MDQ'])\n",
    "    resultsC['peakSlope_mean'] = statistics.mean(dataCOVAREP_Voiced['peakSlope'])\n",
    "    resultsC['RdShape_mean'] = statistics.mean(dataCOVAREP_Voiced['RdShape'])\n",
    "    resultsC['Rd_Conf_mean'] = statistics.mean(dataCOVAREP_Voiced['Rd_Conf'])\n",
    "    resultsC['Creak_mean'] = statistics.mean(dataCOVAREP_Voiced['Creak'])\n",
    "    resultsC['MCEP_0_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_0'])\n",
    "    resultsC['MCEP_1_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_1'])\n",
    "    resultsC['MCEP_2_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_2'])\n",
    "    resultsC['MCEP_3_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_3'])\n",
    "    resultsC['MCEP_4_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_4'])\n",
    "    resultsC['MCEP_5_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_5'])\n",
    "    resultsC['MCEP_6_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_6'])\n",
    "    resultsC['MCEP_7_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_7'])\n",
    "    resultsC['MCEP_8_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_8'])\n",
    "    resultsC['MCEP_9_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_9'])\n",
    "    resultsC['MCEP_10_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_10'])\n",
    "    resultsC['MCEP_11_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_11'])\n",
    "    resultsC['MCEP_12_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_12'])\n",
    "    resultsC['MCEP_13_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_13'])\n",
    "    resultsC['MCEP_14_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_14'])\n",
    "    resultsC['MCEP_15_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_15'])\n",
    "    resultsC['MCEP_16_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_16'])\n",
    "    resultsC['MCEP_17_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_17'])\n",
    "    resultsC['MCEP_18_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_18'])\n",
    "    resultsC['MCEP_19_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_19'])\n",
    "    resultsC['MCEP_20_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_20'])\n",
    "    resultsC['MCEP_21_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_21'])\n",
    "    resultsC['MCEP_22_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_22'])\n",
    "    resultsC['MCEP_23_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_23'])\n",
    "    resultsC['MCEP_24_mean'] = statistics.mean(dataCOVAREP_Voiced['MCEP_24'])\n",
    "    resultsC['HMPDM_0_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_0'])\n",
    "    resultsC['HMPDM_1_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_1'])\n",
    "    resultsC['HMPDM_2_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_2'])\n",
    "    resultsC['HMPDM_3_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_3'])\n",
    "    resultsC['HMPDM_4_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_4'])\n",
    "    resultsC['HMPDM_5_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_5'])\n",
    "    resultsC['HMPDM_6_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_6'])\n",
    "    resultsC['HMPDM_7_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_7'])\n",
    "    resultsC['HMPDM_8_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_8'])\n",
    "    resultsC['HMPDM_9_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_9'])\n",
    "    resultsC['HMPDM_10_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_10'])\n",
    "    resultsC['HMPDM_11_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_11'])\n",
    "    resultsC['HMPDM_12_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_12'])\n",
    "    resultsC['HMPDM_13_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_13'])\n",
    "    resultsC['HMPDM_14_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_14'])\n",
    "    resultsC['HMPDM_15_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_15'])\n",
    "    resultsC['HMPDM_16_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_16'])\n",
    "    resultsC['HMPDM_17_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_17'])\n",
    "    resultsC['HMPDM_18_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_18'])\n",
    "    resultsC['HMPDM_19_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_19'])\n",
    "    resultsC['HMPDM_20_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_20'])\n",
    "    resultsC['HMPDM_21_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_21'])\n",
    "    resultsC['HMPDM_22_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_22'])\n",
    "    resultsC['HMPDM_23_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_23'])\n",
    "    resultsC['HMPDM_24_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDM_24'])\n",
    "    resultsC['HMPDD_0_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDD_0'])\n",
    "    resultsC['HMPDD_1_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDD_1'])\n",
    "    resultsC['HMPDD_2_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDD_2'])\n",
    "    resultsC['HMPDD_3_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDD_3'])\n",
    "    resultsC['HMPDD_4_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDD_4'])\n",
    "    resultsC['HMPDD_5_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDD_5'])\n",
    "    resultsC['HMPDD_6_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDD_6'])\n",
    "    resultsC['HMPDD_7_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDD_7'])\n",
    "    resultsC['HMPDD_8_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDD_8'])\n",
    "    resultsC['HMPDD_9_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDD_9'])\n",
    "    resultsC['HMPDD_10_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDD_10'])\n",
    "    resultsC['HMPDD_11_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDD_11'])\n",
    "    resultsC['HMPDD_12_mean'] = statistics.mean(dataCOVAREP_Voiced['HMPDD_12'])\n",
    "\n",
    "    resultsC['F0_C_median'] = statistics.median(dataCOVAREP_Voiced['F0'])\n",
    "    resultsC['NAQ_median'] = statistics.median(dataCOVAREP_Voiced['NAQ'])\n",
    "    resultsC['QoQ_median'] = statistics.median(dataCOVAREP_Voiced['QoQ'])\n",
    "    resultsC['H1H2_median'] = statistics.median(dataCOVAREP_Voiced['H1H2'])\n",
    "    resultsC['PSP_median'] = statistics.median(dataCOVAREP_Voiced['PSP'])\n",
    "    resultsC['MDQ_median'] = statistics.median(dataCOVAREP_Voiced['MDQ'])\n",
    "    resultsC['peakSlope_median'] = statistics.median(dataCOVAREP_Voiced['peakSlope'])\n",
    "    resultsC['RdShape_median'] = statistics.median(dataCOVAREP_Voiced['RdShape'])\n",
    "    resultsC['Rd_Conf_median'] = statistics.median(dataCOVAREP_Voiced['Rd_Conf'])\n",
    "    resultsC['Creak_median'] = statistics.median(dataCOVAREP_Voiced['Creak'])\n",
    "    resultsC['MCEP_0_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_0'])\n",
    "    resultsC['MCEP_1_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_1'])\n",
    "    resultsC['MCEP_2_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_2'])\n",
    "    resultsC['MCEP_3_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_3'])\n",
    "    resultsC['MCEP_4_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_4'])\n",
    "    resultsC['MCEP_5_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_5'])\n",
    "    resultsC['MCEP_6_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_6'])\n",
    "    resultsC['MCEP_7_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_7'])\n",
    "    resultsC['MCEP_8_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_8'])\n",
    "    resultsC['MCEP_9_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_9'])\n",
    "    resultsC['MCEP_10_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_10'])\n",
    "    resultsC['MCEP_11_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_11'])\n",
    "    resultsC['MCEP_12_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_12'])\n",
    "    resultsC['MCEP_13_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_13'])\n",
    "    resultsC['MCEP_14_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_14'])\n",
    "    resultsC['MCEP_15_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_15'])\n",
    "    resultsC['MCEP_16_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_16'])\n",
    "    resultsC['MCEP_17_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_17'])\n",
    "    resultsC['MCEP_18_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_18'])\n",
    "    resultsC['MCEP_19_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_19'])\n",
    "    resultsC['MCEP_20_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_20'])\n",
    "    resultsC['MCEP_21_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_21'])\n",
    "    resultsC['MCEP_22_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_22'])\n",
    "    resultsC['MCEP_23_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_23'])\n",
    "    resultsC['MCEP_24_median'] = statistics.median(dataCOVAREP_Voiced['MCEP_24'])\n",
    "    resultsC['HMPDM_0_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_0'])\n",
    "    resultsC['HMPDM_1_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_1'])\n",
    "    resultsC['HMPDM_2_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_2'])\n",
    "    resultsC['HMPDM_3_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_3'])\n",
    "    resultsC['HMPDM_4_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_4'])\n",
    "    resultsC['HMPDM_5_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_5'])\n",
    "    resultsC['HMPDM_6_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_6'])\n",
    "    resultsC['HMPDM_7_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_7'])\n",
    "    resultsC['HMPDM_8_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_8'])\n",
    "    resultsC['HMPDM_9_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_9'])\n",
    "    resultsC['HMPDM_10_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_10'])\n",
    "    resultsC['HMPDM_11_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_11'])\n",
    "    resultsC['HMPDM_12_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_12'])\n",
    "    resultsC['HMPDM_13_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_13'])\n",
    "    resultsC['HMPDM_14_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_14'])\n",
    "    resultsC['HMPDM_15_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_15'])\n",
    "    resultsC['HMPDM_16_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_16'])\n",
    "    resultsC['HMPDM_17_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_17'])\n",
    "    resultsC['HMPDM_18_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_18'])\n",
    "    resultsC['HMPDM_19_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_19'])\n",
    "    resultsC['HMPDM_20_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_20'])\n",
    "    resultsC['HMPDM_21_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_21'])\n",
    "    resultsC['HMPDM_22_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_22'])\n",
    "    resultsC['HMPDM_23_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_23'])\n",
    "    resultsC['HMPDM_24_median'] = statistics.median(dataCOVAREP_Voiced['HMPDM_24'])\n",
    "    resultsC['HMPDD_0_median'] = statistics.median(dataCOVAREP_Voiced['HMPDD_0'])\n",
    "    resultsC['HMPDD_1_median'] = statistics.median(dataCOVAREP_Voiced['HMPDD_1'])\n",
    "    resultsC['HMPDD_2_median'] = statistics.median(dataCOVAREP_Voiced['HMPDD_2'])\n",
    "    resultsC['HMPDD_3_median'] = statistics.median(dataCOVAREP_Voiced['HMPDD_3'])\n",
    "    resultsC['HMPDD_4_median'] = statistics.median(dataCOVAREP_Voiced['HMPDD_4'])\n",
    "    resultsC['HMPDD_5_median'] = statistics.median(dataCOVAREP_Voiced['HMPDD_5'])\n",
    "    resultsC['HMPDD_6_median'] = statistics.median(dataCOVAREP_Voiced['HMPDD_6'])\n",
    "    resultsC['HMPDD_7_median'] = statistics.median(dataCOVAREP_Voiced['HMPDD_7'])\n",
    "    resultsC['HMPDD_8_median'] = statistics.median(dataCOVAREP_Voiced['HMPDD_8'])\n",
    "    resultsC['HMPDD_9_median'] = statistics.median(dataCOVAREP_Voiced['HMPDD_9'])\n",
    "    resultsC['HMPDD_10_median'] = statistics.median(dataCOVAREP_Voiced['HMPDD_10'])\n",
    "    resultsC['HMPDD_11_median'] = statistics.median(dataCOVAREP_Voiced['HMPDD_11'])\n",
    "    resultsC['HMPDD_12_median'] = statistics.median(dataCOVAREP_Voiced['HMPDD_12'])\n",
    "\n",
    "    resultsC['F0_C_sd'] = statistics.pstdev(dataCOVAREP_Voiced['F0'])\n",
    "    resultsC['NAQ_sd'] = statistics.pstdev(dataCOVAREP_Voiced['NAQ'])\n",
    "    resultsC['QoQ_sd'] = statistics.pstdev(dataCOVAREP_Voiced['QoQ'])\n",
    "    resultsC['H1H2_sd'] = statistics.pstdev(dataCOVAREP_Voiced['H1H2'])\n",
    "    resultsC['PSP_sd'] = statistics.pstdev(dataCOVAREP_Voiced['PSP'])\n",
    "    resultsC['MDQ_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MDQ'])\n",
    "    resultsC['peakSlope_sd'] = statistics.pstdev(dataCOVAREP_Voiced['peakSlope'])\n",
    "    resultsC['RdShape_sd'] = statistics.pstdev(dataCOVAREP_Voiced['RdShape'])\n",
    "    resultsC['Rd_Conf_sd'] = statistics.pstdev(dataCOVAREP_Voiced['Rd_Conf'])\n",
    "    resultsC['Creak_sd'] = statistics.pstdev(dataCOVAREP_Voiced['Creak'])\n",
    "    resultsC['MCEP_0_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_0'])\n",
    "    resultsC['MCEP_1_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_1'])\n",
    "    resultsC['MCEP_2_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_2'])\n",
    "    resultsC['MCEP_3_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_3'])\n",
    "    resultsC['MCEP_4_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_4'])\n",
    "    resultsC['MCEP_5_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_5'])\n",
    "    resultsC['MCEP_6_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_6'])\n",
    "    resultsC['MCEP_7_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_7'])\n",
    "    resultsC['MCEP_8_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_8'])\n",
    "    resultsC['MCEP_9_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_9'])\n",
    "    resultsC['MCEP_10_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_10'])\n",
    "    resultsC['MCEP_11_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_11'])\n",
    "    resultsC['MCEP_12_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_12'])\n",
    "    resultsC['MCEP_13_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_13'])\n",
    "    resultsC['MCEP_14_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_14'])\n",
    "    resultsC['MCEP_15_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_15'])\n",
    "    resultsC['MCEP_16_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_16'])\n",
    "    resultsC['MCEP_17_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_17'])\n",
    "    resultsC['MCEP_18_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_18'])\n",
    "    resultsC['MCEP_19_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_19'])\n",
    "    resultsC['MCEP_20_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_20'])\n",
    "    resultsC['MCEP_21_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_21'])\n",
    "    resultsC['MCEP_22_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_22'])\n",
    "    resultsC['MCEP_23_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_23'])\n",
    "    resultsC['MCEP_24_sd'] = statistics.pstdev(dataCOVAREP_Voiced['MCEP_24'])\n",
    "    resultsC['HMPDM_0_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_0'])\n",
    "    resultsC['HMPDM_1_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_1'])\n",
    "    resultsC['HMPDM_2_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_2'])\n",
    "    resultsC['HMPDM_3_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_3'])\n",
    "    resultsC['HMPDM_4_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_4'])\n",
    "    resultsC['HMPDM_5_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_5'])\n",
    "    resultsC['HMPDM_6_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_6'])\n",
    "    resultsC['HMPDM_7_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_7'])\n",
    "    resultsC['HMPDM_8_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_8'])\n",
    "    resultsC['HMPDM_9_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_9'])\n",
    "    resultsC['HMPDM_10_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_10'])\n",
    "    resultsC['HMPDM_11_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_11'])\n",
    "    resultsC['HMPDM_12_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_12'])\n",
    "    resultsC['HMPDM_13_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_13'])\n",
    "    resultsC['HMPDM_14_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_14'])\n",
    "    resultsC['HMPDM_15_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_15'])\n",
    "    resultsC['HMPDM_16_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_16'])\n",
    "    resultsC['HMPDM_17_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_17'])\n",
    "    resultsC['HMPDM_18_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_18'])\n",
    "    resultsC['HMPDM_19_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_19'])\n",
    "    resultsC['HMPDM_20_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_20'])\n",
    "    resultsC['HMPDM_21_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_21'])\n",
    "    resultsC['HMPDM_22_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_22'])\n",
    "    resultsC['HMPDM_23_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_23'])\n",
    "    resultsC['HMPDM_24_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDM_24'])\n",
    "    resultsC['HMPDD_0_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDD_0'])\n",
    "    resultsC['HMPDD_1_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDD_1'])\n",
    "    resultsC['HMPDD_2_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDD_2'])\n",
    "    resultsC['HMPDD_3_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDD_3'])\n",
    "    resultsC['HMPDD_4_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDD_4'])\n",
    "    resultsC['HMPDD_5_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDD_5'])\n",
    "    resultsC['HMPDD_6_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDD_6'])\n",
    "    resultsC['HMPDD_7_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDD_7'])\n",
    "    resultsC['HMPDD_8_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDD_8'])\n",
    "    resultsC['HMPDD_9_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDD_9'])\n",
    "    resultsC['HMPDD_10_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDD_10'])\n",
    "    resultsC['HMPDD_11_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDD_11'])\n",
    "    resultsC['HMPDD_12_sd'] = statistics.pstdev(dataCOVAREP_Voiced['HMPDD_12'])\n",
    "\n",
    "    resultsC = resultsC.drop(resultsC.columns[[0]],axis = 1)\n",
    "\n",
    "    return resultsC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80a6a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_power_spec (wavefile):\n",
    "    mean_power_per_band_per_channel = []\n",
    "    freq_bands = {\"band1\" : [0,500],\n",
    "              \"band2\" : [500,1000],\n",
    "              \"band3\" : [1000, 1500],\n",
    "              \"band4\" : [1500, 2000]\n",
    "               }\n",
    "    data, sample_rate = librosa.load(wave_file)\n",
    "\n",
    "    \n",
    "    freq, spectrum =scipy.signal.welch(data, fs=sample_rate, window='hamming', nperseg=100, \n",
    "                   noverlap=0.0, nfft=1024, detrend='constant', \n",
    "                   return_onesided=True, scaling='density', axis=- 1, \n",
    "                   average='mean')\n",
    "    frequencies_indexes = [np.logical_and(freq >= band[0], freq <= band[1]) for band in freq_bands.values()]\n",
    "    mean_power_per_band_per_channel += [np.mean(spectrum[idx]) for idx in frequencies_indexes]\n",
    "    \n",
    "    band_1_perct_spec_energy = mean_power_per_band_per_channel[0] / sum(mean_power_per_band_per_channel)\n",
    "    band_2_perct_spec_energy = mean_power_per_band_per_channel[1] / sum(mean_power_per_band_per_channel)\n",
    "    band_3_perct_spec_energy = mean_power_per_band_per_channel[2] / sum(mean_power_per_band_per_channel)\n",
    "    band_4_perct_spec_energy = mean_power_per_band_per_channel[3] / sum(mean_power_per_band_per_channel)\n",
    "    \n",
    "    return band_1_perct_spec_energy, band_2_perct_spec_energy, band_3_perct_spec_energy, band_4_perct_spec_energy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c807ea",
   "metadata": {},
   "source": [
    "#### CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61594c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists to put the results\n",
    "file_list = []\n",
    "duration_list = []\n",
    "mean_F0_list = []\n",
    "sd_F0_list = []\n",
    "hnr_list = []\n",
    "localJitter_list = []\n",
    "localabsoluteJitter_list = []\n",
    "rapJitter_list = []\n",
    "ppq5Jitter_list = []\n",
    "ddpJitter_list = []\n",
    "localShimmer_list = []\n",
    "localdbShimmer_list = []\n",
    "apq3Shimmer_list = []\n",
    "aqpq5Shimmer_list = []\n",
    "apq11Shimmer_list = []\n",
    "ddaShimmer_list = []\n",
    "f1_mean_list = []\n",
    "f2_mean_list = []\n",
    "f3_mean_list = []\n",
    "f4_mean_list = []\n",
    "f1_median_list = []\n",
    "f2_median_list = []\n",
    "f3_median_list = []\n",
    "f4_median_list = []\n",
    "f1_sd_list = []\n",
    "f2_sd_list = []\n",
    "f3_sd_list = []\n",
    "f4_sd_list = []\n",
    "patient_id_list = []\n",
    "\n",
    "spec_cen_list = []\n",
    "spec_cen_relF0_mean_mean_list = []\n",
    "spec_cen_relF0_mean_sd_list = []\n",
    "spec_cen_relF0_mean_median_list = []\n",
    "spec_cen_m_mean_d_sd_mean_list = []\n",
    "spec_cen_m_mean_d_sd_sd_list =[]\n",
    "spec_cen_m_mean_d_sd_median_list = []\n",
    "\n",
    "PHQ8_Binary_list = []\n",
    "PHQ8_Score_list = []\n",
    "Gender_list = []\n",
    "data_set_list = []\n",
    "patient_id_list = []\n",
    "min_F0_list = []\n",
    "max_F0_list = []\n",
    "\n",
    "max_rel_F0range_d_mean_list = []\n",
    "min_rel_F0range_d_mean_list = []\n",
    "sd_rel_F0range_d_mean_list = []\n",
    "mean_rel_F0range_d_mean_list = []\n",
    "\n",
    "max_rel_F0range_m_mean_d_sd_list = []\n",
    "min_rel_F0range_m_mean_d_sd_list = []\n",
    "sd_rel_F0range_m_mean_d_sd_list = []\n",
    "mean_rel_F0range_m_mean_d_sd_list = []\n",
    "\n",
    "max_rel_F0grad_d_mean_list = []\n",
    "min_rel_F0grad_d_mean_list = []\n",
    "sd_rel_F0grad_d_mean_list = []\n",
    "mean_rel_F0grad_d_mean_list = []\n",
    "\n",
    "max_rel_F0grad_m_mean_d_sd_list = []\n",
    "min_rel_F0grad_m_mean_d_sd_list = []\n",
    "sd_rel_F0grad_m_mean_d_sd_list = []\n",
    "mean_rel_F0grad_m_mean_d_sd_list = []\n",
    "\n",
    "F0_dev_step_mean_list = []\n",
    "F0_dev_step_max_list = []\n",
    "\n",
    "\n",
    "band1_spec_energy_perct_list = []\n",
    "band2_spec_energy_perct_list = []\n",
    "band3_spec_energy_perct_list = []\n",
    "band4_spec_energy_perct_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ba19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "074babf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started File 0\n",
      "Finished File 0\n",
      "Started File 1\n",
      "Finished File 1\n",
      "Started File 2\n",
      "Finished File 2\n",
      "Started File 3\n",
      "Finished File 3\n",
      "Started File 4\n",
      "Finished File 4\n",
      "Started File 5\n",
      "Finished File 5\n",
      "Started File 6\n",
      "Finished File 6\n",
      "Started File 7\n",
      "Finished File 7\n",
      "Started File 8\n",
      "Finished File 8\n",
      "Started File 9\n",
      "Finished File 9\n",
      "Started File 10\n",
      "Finished File 10\n",
      "Started File 11\n",
      "Finished File 11\n",
      "Started File 12\n",
      "Finished File 12\n",
      "Started File 13\n",
      "Finished File 13\n",
      "Started File 14\n",
      "Finished File 14\n",
      "Started File 15\n",
      "Finished File 15\n",
      "Started File 16\n",
      "Finished File 16\n",
      "Started File 17\n",
      "Finished File 17\n",
      "Started File 18\n",
      "Finished File 18\n",
      "Started File 19\n",
      "Finished File 19\n",
      "Started File 20\n",
      "Finished File 20\n",
      "Started File 21\n",
      "Finished File 21\n",
      "Started File 22\n",
      "Finished File 22\n",
      "Started File 23\n",
      "Finished File 23\n",
      "Started File 24\n",
      "Finished File 24\n",
      "Started File 25\n",
      "Finished File 25\n",
      "Started File 26\n",
      "Finished File 26\n",
      "Started File 27\n",
      "Finished File 27\n",
      "Started File 28\n",
      "Finished File 28\n",
      "Started File 29\n",
      "Finished File 29\n",
      "Started File 30\n",
      "Finished File 30\n",
      "Started File 31\n",
      "Finished File 31\n",
      "Started File 32\n",
      "Finished File 32\n",
      "Started File 33\n",
      "Finished File 33\n",
      "Started File 34\n",
      "Finished File 34\n",
      "Started File 35\n",
      "Finished File 35\n",
      "Started File 36\n",
      "Finished File 36\n",
      "Started File 37\n",
      "Finished File 37\n",
      "Started File 38\n",
      "Finished File 38\n",
      "Started File 39\n",
      "Finished File 39\n",
      "Started File 40\n",
      "Finished File 40\n",
      "Started File 41\n",
      "Finished File 41\n",
      "Started File 42\n",
      "Finished File 42\n",
      "Started File 43\n",
      "Finished File 43\n",
      "Started File 44\n",
      "Finished File 44\n",
      "Started File 45\n",
      "Finished File 45\n",
      "Started File 46\n",
      "Finished File 46\n",
      "Started File 47\n",
      "Finished File 47\n",
      "Started File 48\n",
      "Finished File 48\n",
      "Started File 49\n",
      "Finished File 49\n",
      "Started File 50\n",
      "Finished File 50\n",
      "Started File 51\n",
      "Finished File 51\n",
      "Started File 52\n",
      "Finished File 52\n",
      "Started File 53\n",
      "Finished File 53\n",
      "Started File 54\n",
      "Finished File 54\n",
      "Started File 55\n",
      "Finished File 55\n",
      "Started File 56\n",
      "Finished File 56\n",
      "Started File 57\n",
      "Finished File 57\n",
      "Started File 58\n",
      "Finished File 58\n",
      "Started File 59\n",
      "Finished File 59\n",
      "Started File 60\n",
      "Finished File 60\n",
      "Started File 61\n",
      "Finished File 61\n",
      "Started File 62\n",
      "Finished File 62\n",
      "Started File 63\n",
      "Finished File 63\n",
      "Started File 64\n",
      "Finished File 64\n",
      "Started File 65\n",
      "Finished File 65\n",
      "Started File 66\n",
      "Finished File 66\n",
      "Started File 67\n",
      "Finished File 67\n",
      "Started File 68\n",
      "Finished File 68\n",
      "Started File 69\n",
      "Finished File 69\n",
      "Started File 70\n",
      "Finished File 70\n",
      "Started File 71\n",
      "Finished File 71\n",
      "Started File 72\n",
      "Finished File 72\n",
      "Started File 73\n",
      "Finished File 73\n",
      "Started File 74\n",
      "Finished File 74\n",
      "Started File 75\n",
      "Finished File 75\n",
      "Started File 76\n",
      "Finished File 76\n",
      "Started File 77\n",
      "Finished File 77\n",
      "Started File 78\n",
      "Finished File 78\n",
      "Started File 79\n",
      "Finished File 79\n",
      "Started File 80\n",
      "Finished File 80\n",
      "Started File 81\n",
      "Finished File 81\n",
      "Started File 82\n",
      "Finished File 82\n",
      "Started File 83\n",
      "Finished File 83\n",
      "Started File 84\n",
      "Finished File 84\n",
      "Started File 85\n",
      "Finished File 85\n",
      "Started File 86\n",
      "Finished File 86\n",
      "Started File 87\n",
      "Finished File 87\n",
      "Started File 88\n",
      "Finished File 88\n",
      "Started File 89\n",
      "Finished File 89\n",
      "Started File 90\n",
      "Finished File 90\n",
      "Started File 91\n",
      "Finished File 91\n",
      "Started File 92\n",
      "Finished File 92\n",
      "Started File 93\n",
      "Finished File 93\n",
      "Started File 94\n",
      "Finished File 94\n",
      "Started File 95\n",
      "Finished File 95\n",
      "Started File 96\n",
      "Finished File 96\n",
      "Started File 97\n",
      "Finished File 97\n",
      "Started File 98\n",
      "Finished File 98\n",
      "Started File 99\n",
      "Finished File 99\n",
      "Started File 100\n",
      "Finished File 100\n",
      "Started File 101\n",
      "Finished File 101\n",
      "Started File 102\n",
      "Finished File 102\n",
      "Started File 103\n",
      "Finished File 103\n",
      "Started File 104\n",
      "Finished File 104\n",
      "Started File 105\n",
      "Finished File 105\n",
      "Started File 106\n",
      "Finished File 106\n",
      "Started File 107\n",
      "Finished File 107\n",
      "Started File 108\n",
      "Finished File 108\n",
      "Started File 109\n",
      "Finished File 109\n",
      "Started File 110\n",
      "Finished File 110\n",
      "Started File 111\n",
      "Finished File 111\n",
      "Started File 112\n",
      "Finished File 112\n",
      "Started File 113\n",
      "Finished File 113\n",
      "Started File 114\n",
      "Finished File 114\n",
      "Started File 115\n",
      "Finished File 115\n",
      "Started File 116\n",
      "Finished File 116\n",
      "Started File 117\n",
      "Finished File 117\n",
      "Started File 118\n",
      "Finished File 118\n",
      "Started File 119\n",
      "Finished File 119\n",
      "Started File 120\n",
      "Finished File 120\n",
      "Started File 121\n",
      "Finished File 121\n",
      "Started File 122\n",
      "Finished File 122\n",
      "Started File 123\n",
      "Finished File 123\n",
      "Started File 124\n",
      "Finished File 124\n",
      "Started File 125\n",
      "Finished File 125\n",
      "Started File 126\n",
      "Finished File 126\n",
      "Started File 127\n",
      "Finished File 127\n",
      "Started File 128\n",
      "Finished File 128\n",
      "Started File 129\n",
      "Finished File 129\n",
      "Started File 130\n",
      "Finished File 130\n",
      "Started File 131\n",
      "Finished File 131\n",
      "Started File 132\n",
      "Finished File 132\n",
      "Started File 133\n",
      "Finished File 133\n",
      "Started File 134\n",
      "Finished File 134\n",
      "Started File 135\n",
      "Finished File 135\n",
      "Started File 136\n",
      "Finished File 136\n",
      "Started File 137\n",
      "Finished File 137\n",
      "Started File 138\n",
      "Finished File 138\n",
      "Started File 139\n",
      "Finished File 139\n",
      "Started File 140\n",
      "Finished File 140\n",
      "Started File 141\n",
      "Finished File 141\n",
      "Started File 142\n",
      "Finished File 142\n",
      "Started File 143\n",
      "Finished File 143\n",
      "Started File 144\n",
      "Finished File 144\n",
      "Started File 145\n",
      "Finished File 145\n",
      "Started File 146\n",
      "Finished File 146\n",
      "Started File 147\n",
      "Finished File 147\n",
      "Started File 148\n",
      "Finished File 148\n",
      "Started File 149\n",
      "Finished File 149\n",
      "Started File 150\n",
      "Finished File 150\n",
      "Started File 151\n",
      "Finished File 151\n",
      "Started File 152\n",
      "Finished File 152\n",
      "Started File 153\n",
      "Finished File 153\n",
      "Started File 154\n",
      "Finished File 154\n",
      "Started File 155\n",
      "Finished File 155\n",
      "Started File 156\n",
      "Finished File 156\n",
      "Started File 157\n",
      "Finished File 157\n",
      "Started File 158\n",
      "Finished File 158\n",
      "Started File 159\n",
      "Finished File 159\n",
      "Started File 160\n",
      "Finished File 160\n",
      "Started File 161\n",
      "Finished File 161\n",
      "Started File 162\n",
      "Finished File 162\n",
      "Started File 163\n",
      "Finished File 163\n",
      "Started File 164\n",
      "Finished File 164\n",
      "Started File 165\n",
      "Finished File 165\n",
      "Started File 166\n",
      "Finished File 166\n",
      "Started File 167\n",
      "Finished File 167\n",
      "Started File 168\n",
      "Finished File 168\n",
      "Started File 169\n",
      "Finished File 169\n",
      "Started File 170\n",
      "Finished File 170\n",
      "Started File 171\n",
      "Finished File 171\n",
      "Started File 172\n",
      "Finished File 172\n",
      "Started File 173\n",
      "Finished File 173\n",
      "Started File 174\n",
      "Finished File 174\n",
      "Started File 175\n",
      "Finished File 175\n",
      "Started File 176\n",
      "Finished File 176\n",
      "Started File 177\n",
      "Finished File 177\n",
      "Started File 178\n",
      "Finished File 178\n",
      "Started File 179\n",
      "Finished File 179\n",
      "Started File 180\n",
      "Finished File 180\n",
      "Started File 181\n",
      "Finished File 181\n",
      "Started File 182\n",
      "Finished File 182\n",
      "Started File 183\n",
      "Finished File 183\n",
      "Started File 184\n",
      "Finished File 184\n",
      "Started File 185\n",
      "Finished File 185\n"
     ]
    }
   ],
   "source": [
    "# Go through all the wave files in the folder and measure all the acoustics\n",
    "count = 0\n",
    "\n",
    "for wave_file in glob.glob(fileGlob):\n",
    "    print(\"Started File \" + str(count))\n",
    "    sound = parselmouth.Sound(wave_file)\n",
    "    patient_id = wave_file[-7:-4]\n",
    "    \n",
    "    dataDemographic = demoTableCreate()\n",
    "    (Data_set, PHQ8_Binary, PHQ8_Score, Gender) = demographicInfo(patient_id)\n",
    "    \n",
    "    (duration, meanF0, minF0, maxF0, stdevF0, hnr, localJitter, localabsoluteJitter, rapJitter, ppq5Jitter, \n",
    "     ddpJitter, localShimmer, localdbShimmer, apq3Shimmer, aqpq5Shimmer, apq11Shimmer, ddaShimmer, max_rel_F0grad_d_mean, \n",
    "     min_rel_F0grad_d_mean, sd_rel_F0grad_d_mean, mean_rel_F0grad_d_mean, max_rel_F0grad_m_mean_d_sd, \n",
    "     min_rel_F0grad_m_mean_d_sd, sd_rel_F0grad_m_mean_d_sd, mean_rel_F0grad_m_mean_d_sd,\n",
    "     max_rel_F0range_d_mean, min_rel_F0range_d_mean, sd_rel_F0range_d_mean, mean_rel_F0range_d_mean, \n",
    "     max_rel_F0range_m_mean_d_sd, min_rel_F0range_m_mean_d_sd, sd_rel_F0range_m_mean_d_sd, mean_rel_F0range_m_mean_d_sd,\n",
    "     F0_dev_step_mean, F0_dev_step_max) = measurePitch(sound, 75, 300, \"Hertz\")\n",
    "    \n",
    "    \n",
    "    (f1_mean, f2_mean, f3_mean, f4_mean, f1_median, f2_median, f3_median, f4_median, f1_sd, f2_sd, f3_sd, f4_sd) = measureFormants(\n",
    "        sound, wave_file, 75, 300)\n",
    "    \n",
    "    (spec_cen_relF0_mean_mean, spec_cen_relF0_mean_sd, spec_cen_relF0_mean_median,\n",
    "    spec_cen_m_mean_d_sd_mean, spec_cen_m_mean_d_sd_sd, spec_cen_m_mean_d_sd_median)= spec_centoid(wave_file, meanF0, stdevF0)\n",
    "\n",
    "    \n",
    "    \n",
    "    (band_1_perct_spec_energy, band_2_perct_spec_energy, band_3_perct_spec_energy, band_4_perct_spec_energy) = band_power_spec(wave_file)\n",
    "    \n",
    "    #data pitch based\n",
    "    duration_list.append(duration) # make duration list\n",
    "    mean_F0_list.append(meanF0) # make a mean F0 list\n",
    "    min_F0_list.append(minF0)\n",
    "    max_F0_list.append(maxF0)\n",
    "    sd_F0_list.append(stdevF0) # make a sd F0 list\n",
    "    hnr_list.append(hnr) #add HNR data\n",
    "    \n",
    "    #data relatives of F0 abs gradient \n",
    "    max_rel_F0grad_d_mean_list.append(max_rel_F0grad_d_mean)\n",
    "    min_rel_F0grad_d_mean_list.append(min_rel_F0grad_d_mean)\n",
    "    sd_rel_F0grad_d_mean_list.append(sd_rel_F0grad_d_mean)\n",
    "    mean_rel_F0grad_d_mean_list.append(mean_rel_F0grad_d_mean)\n",
    "\n",
    "    max_rel_F0grad_m_mean_d_sd_list.append(max_rel_F0grad_m_mean_d_sd)\n",
    "    min_rel_F0grad_m_mean_d_sd_list.append(min_rel_F0grad_m_mean_d_sd)\n",
    "    sd_rel_F0grad_m_mean_d_sd_list.append(sd_rel_F0grad_m_mean_d_sd)\n",
    "    mean_rel_F0grad_m_mean_d_sd_list.append(mean_rel_F0grad_m_mean_d_sd)\n",
    "\n",
    "    #data relatives of F0 abs range \n",
    "    max_rel_F0range_d_mean_list.append(max_rel_F0range_d_mean)\n",
    "    min_rel_F0range_d_mean_list.append(min_rel_F0range_d_mean)\n",
    "    sd_rel_F0range_d_mean_list.append(sd_rel_F0range_d_mean)\n",
    "    mean_rel_F0range_d_mean_list.append(mean_rel_F0range_d_mean)\n",
    "\n",
    "    max_rel_F0range_m_mean_d_sd_list.append(max_rel_F0range_m_mean_d_sd)\n",
    "    min_rel_F0range_m_mean_d_sd_list.append(min_rel_F0range_m_mean_d_sd)\n",
    "    sd_rel_F0range_m_mean_d_sd_list.append(sd_rel_F0range_m_mean_d_sd)\n",
    "    mean_rel_F0range_m_mean_d_sd_list.append(mean_rel_F0range_m_mean_d_sd)\n",
    "    \n",
    "    F0_dev_step_mean_list.append(F0_dev_step_mean) \n",
    "    F0_dev_step_max_list.append(F0_dev_step_max)\n",
    "    \n",
    "    # add raw jitter and shimmer measures\n",
    "    localJitter_list.append(localJitter)\n",
    "    localabsoluteJitter_list.append(localabsoluteJitter)\n",
    "    rapJitter_list.append(rapJitter)\n",
    "    ppq5Jitter_list.append(ppq5Jitter)\n",
    "    ddpJitter_list.append(ddpJitter)\n",
    "    localShimmer_list.append(localShimmer)\n",
    "    localdbShimmer_list.append(localdbShimmer)\n",
    "    apq3Shimmer_list.append(apq3Shimmer)\n",
    "    aqpq5Shimmer_list.append(aqpq5Shimmer)\n",
    "    apq11Shimmer_list.append(apq11Shimmer)\n",
    "    ddaShimmer_list.append(ddaShimmer)\n",
    "    \n",
    "    # add the formant data\n",
    "    f1_mean_list.append(f1_mean)\n",
    "    f2_mean_list.append(f2_mean)\n",
    "    f3_mean_list.append(f3_mean)\n",
    "    f4_mean_list.append(f4_mean)\n",
    "    f1_median_list.append(f1_median)\n",
    "    f2_median_list.append(f2_median)\n",
    "    f3_median_list.append(f3_median)\n",
    "    f4_median_list.append(f4_median)\n",
    "    f1_sd_list.append(f1_sd)\n",
    "    f2_sd_list.append(f2_sd)\n",
    "    f3_sd_list.append(f3_sd)\n",
    "    f4_sd_list.append(f4_sd)\n",
    "    \n",
    "    # add spec_cen data\n",
    "    spec_cen_relF0_mean_mean_list.append(spec_cen_relF0_mean_mean)\n",
    "    spec_cen_relF0_mean_sd_list.append(spec_cen_relF0_mean_sd)\n",
    "    spec_cen_relF0_mean_median_list.append(spec_cen_relF0_mean_median)\n",
    "    spec_cen_m_mean_d_sd_mean_list.append(spec_cen_m_mean_d_sd_mean)\n",
    "    spec_cen_m_mean_d_sd_sd_list.append(spec_cen_m_mean_d_sd_sd)\n",
    "    spec_cen_m_mean_d_sd_median_list.append(spec_cen_m_mean_d_sd_median)    \n",
    "\n",
    "    \n",
    "    \n",
    "    #bandwidth energy percentages\n",
    "    band1_spec_energy_perct_list.append(band_1_perct_spec_energy)\n",
    "    band2_spec_energy_perct_list.append(band_2_perct_spec_energy)\n",
    "    band3_spec_energy_perct_list.append(band_3_perct_spec_energy)\n",
    "    band4_spec_energy_perct_list.append(band_4_perct_spec_energy)\n",
    "\n",
    "    # patient number data\n",
    "    \n",
    "    patient_id_list.append(patient_id)\n",
    "    \n",
    "    # demographic data\n",
    "    PHQ8_Binary_list.append(PHQ8_Binary)\n",
    "    PHQ8_Score_list.append(PHQ8_Score)\n",
    "    Gender_list.append(Gender)\n",
    "    data_set_list.append(Data_set)\n",
    "    \n",
    "    print(\"Finished File \" + str(count))\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0b654e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the data to Pandas\n",
    "\n",
    "\n",
    "\n",
    "dataDavid = pd.DataFrame(np.column_stack([patient_id_list, data_set_list, PHQ8_Binary_list, PHQ8_Score_list, Gender_list, \n",
    "                                            duration_list, mean_F0_list, sd_F0_list, min_F0_list, max_F0_list,\n",
    "                                            band1_spec_energy_perct_list, band2_spec_energy_perct_list, \n",
    "                                            band3_spec_energy_perct_list, band4_spec_energy_perct_list, hnr_list, \n",
    "                                            localJitter_list, localabsoluteJitter_list, rapJitter_list, \n",
    "                                            ppq5Jitter_list, ddpJitter_list, localShimmer_list, \n",
    "                                            localdbShimmer_list, apq3Shimmer_list, aqpq5Shimmer_list, \n",
    "                                            apq11Shimmer_list, ddaShimmer_list, f1_mean_list, \n",
    "                                            f2_mean_list, f3_mean_list, f4_mean_list, \n",
    "                                            f1_median_list, f2_median_list, f3_median_list, \n",
    "                                            f4_median_list, f1_sd_list, f2_sd_list, f3_sd_list, f4_sd_list,spec_cen_relF0_mean_mean_list, \n",
    "                                            spec_cen_relF0_mean_sd_list, spec_cen_relF0_mean_median_list, spec_cen_m_mean_d_sd_mean_list, \n",
    "                                             spec_cen_m_mean_d_sd_sd_list, spec_cen_m_mean_d_sd_median_list,\n",
    "                                             max_rel_F0grad_d_mean_list,min_rel_F0grad_d_mean_list, sd_rel_F0grad_d_mean_list,\n",
    "                                             mean_rel_F0grad_d_mean_list, max_rel_F0grad_m_mean_d_sd_list, min_rel_F0grad_m_mean_d_sd_list,\n",
    "                                             sd_rel_F0grad_m_mean_d_sd_list, mean_rel_F0grad_m_mean_d_sd_list,\n",
    "                                             max_rel_F0range_d_mean_list,min_rel_F0range_d_mean_list, sd_rel_F0range_d_mean_list,\n",
    "                                             mean_rel_F0range_d_mean_list, max_rel_F0range_m_mean_d_sd_list, min_rel_F0range_m_mean_d_sd_list,\n",
    "                                             sd_rel_F0range_m_mean_d_sd_list, mean_rel_F0range_m_mean_d_sd_list, F0_dev_step_mean_list, \n",
    "                                             F0_dev_step_max_list]), dtype=np.float32,\n",
    "                                    columns=['patient_id', 'data_set', 'PHQ8_Binary', 'PHQ8_Score', 'Gender',\n",
    "                                             'duration', 'meanF0Hz', 'stdevF0Hz', 'F0_min', 'F0_max',\n",
    "                                             'Band1_spec_eng_perct', 'Band2_spec_eng_perct', 'Band3_spec_eng_perct',\n",
    "                                             'Band4_spec_eng_perct', 'HNR', \n",
    "                                            'localJitter', 'localabsoluteJitter', 'rapJitter', \n",
    "                                            'ppq5Jitter', 'ddpJitter', 'localShimmer', \n",
    "                                            'localdbShimmer', 'apq3Shimmer', 'apq5Shimmer', \n",
    "                                            'apq11Shimmer', 'ddaShimmer', 'f1_mean', 'f2_mean', \n",
    "                                            'f3_mean', 'f4_mean', 'f1_median', \n",
    "                                            'f2_median', 'f3_median', 'f4_median', 'f1_sd', 'f2_sd', 'f3_sd', 'f4_sd',\n",
    "                                           'spec_cen_mean_relF0' ,  'spec_cen_sd_relF0', 'spec_cen_median_relF0', \n",
    "                                             'spec_cen_mean_mF0dsd', 'spec_cen_sd_mF0dsd', 'spec_cen_median_mF0dsd',\n",
    "                                             'max_rel_F0grad_o_mean', 'min_rel_F0grade_o_mean',\n",
    "                                            'sd_rel_F0grad_o_mean', 'mean_rel_F0grade_o_mean', 'max_rel_F0grad_m_mean_o_sd',\n",
    "                                            'min_rel_F0grade_m_mean_o_sd','sd_rel_F0grad_m_mean_o_sd', 'mean_rel_F0grade_m_mean_o_sd',\n",
    "                                            'max_F0_Range_rel_mean', 'min_F0_Range_rel_mean', 'sd_F0_Range_rel_mean', \n",
    "                                            'mean_F0_Range_rel_mean', 'max_F0_range_m_mean_o_sd', 'min_F0_range_m_mean_o_sd', \n",
    "                                            'sd_F0_range_m_mean_o_sd', 'mean_F0_range_m_mean_o_sd', 'F0_absRange_mean', 'F0_absRange_amx'])\n",
    "pcaData = runPCA(dataDavid) # Run jitter and shimmer PCA\n",
    "#dataDavid = pd.concat([dataDavid, pcaData], axis=1) # Add PCA data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7183688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataDavid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602b0464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "910ab68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDavid['pF'] = (zscore(dataDavid.f1_median) + zscore(dataDavid.f2_median) + zscore(dataDavid.f3_median) + zscore(dataDavid.f4_median)) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d79db6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDavid['fdisp'] = (dataDavid['f4_median'] - dataDavid['f1_median']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fb5c5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDavid['avgFormant'] = (dataDavid['f1_median'] + dataDavid['f2_median'] + dataDavid['f3_median'] + dataDavid['f4_median']) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05015516",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDavid['mff'] = (dataDavid['f1_median'] * dataDavid['f2_median'] * dataDavid['f3_median'] * dataDavid['f4_median']) ** 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0babf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the data again\n",
    "#dataDavid.to_csv(\"processed_results.csv\", index=False)\n",
    "#dataDavid = pd.read_csv('processed_results.csv', header=0)\n",
    "\n",
    "dataDavid['fitch_vtl'] = ((1 * (35000 / (4 * dataDavid['f1_median']))) +\n",
    "                   (3 * (35000 / (4 * dataDavid['f2_median']))) + \n",
    "                   (5 * (35000 / (4 * dataDavid['f3_median']))) + \n",
    "                   (7 * (35000 / (4 * dataDavid['f4_median'])))) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17428543",
   "metadata": {},
   "outputs": [],
   "source": [
    "xysum = (0.5 * dataDavid['f1_median']) + (1.5 * dataDavid['f2_median']) + (2.5 * dataDavid['f3_median']) + (3.5 * dataDavid['f4_median'])\n",
    "xsquaredsum = (0.5 ** 2) + (1.5 ** 2) + (2.5 ** 2) + (3.5 ** 2)\n",
    "dataDavid['delta_f'] = xysum / xsquaredsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b5527c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDavid['vtl_delta_f'] = 35000 / (2 * dataDavid['delta_f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c630dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataDavid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fbaf7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34f9dd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDavid['F0_SD_div_F0_Mean'] = dataDavid['stdevF0Hz'] / dataDavid['meanF0Hz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250a9913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a1aedb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started File 0\n",
      "Finished File 0\n",
      "Started File 1\n",
      "Finished File 1\n",
      "Started File 2\n",
      "Finished File 2\n",
      "Started File 3\n",
      "Finished File 3\n",
      "Started File 4\n",
      "Finished File 4\n",
      "Started File 5\n",
      "Finished File 5\n",
      "Started File 6\n",
      "Finished File 6\n",
      "Started File 7\n",
      "Finished File 7\n",
      "Started File 8\n",
      "Finished File 8\n",
      "Started File 9\n",
      "Finished File 9\n",
      "Started File 10\n",
      "Finished File 10\n",
      "Started File 11\n",
      "Finished File 11\n",
      "Started File 12\n",
      "Finished File 12\n",
      "Started File 13\n",
      "Finished File 13\n",
      "Started File 14\n",
      "Finished File 14\n",
      "Started File 15\n",
      "Finished File 15\n",
      "Started File 16\n",
      "Finished File 16\n",
      "Started File 17\n",
      "Finished File 17\n",
      "Started File 18\n",
      "Finished File 18\n",
      "Started File 19\n",
      "Finished File 19\n",
      "Started File 20\n",
      "Finished File 20\n",
      "Started File 21\n",
      "Finished File 21\n",
      "Started File 22\n",
      "Finished File 22\n",
      "Started File 23\n",
      "Finished File 23\n",
      "Started File 24\n",
      "Finished File 24\n",
      "Started File 25\n",
      "Finished File 25\n",
      "Started File 26\n",
      "Finished File 26\n",
      "Started File 27\n",
      "Finished File 27\n",
      "Started File 28\n",
      "Finished File 28\n",
      "Started File 29\n",
      "Finished File 29\n",
      "Started File 30\n",
      "Finished File 30\n",
      "Started File 31\n",
      "Finished File 31\n",
      "Started File 32\n",
      "Finished File 32\n",
      "Started File 33\n",
      "Finished File 33\n",
      "Started File 34\n",
      "Finished File 34\n",
      "Started File 35\n",
      "Finished File 35\n",
      "Started File 36\n",
      "Finished File 36\n",
      "Started File 37\n",
      "Finished File 37\n",
      "Started File 38\n",
      "Finished File 38\n",
      "Started File 39\n",
      "Finished File 39\n",
      "Started File 40\n",
      "Finished File 40\n",
      "Started File 41\n",
      "Finished File 41\n",
      "Started File 42\n",
      "Finished File 42\n",
      "Started File 43\n",
      "Finished File 43\n",
      "Started File 44\n",
      "Finished File 44\n",
      "Started File 45\n",
      "Finished File 45\n",
      "Started File 46\n",
      "Finished File 46\n",
      "Started File 47\n",
      "Finished File 47\n",
      "Started File 48\n",
      "Finished File 48\n",
      "Started File 49\n",
      "Finished File 49\n",
      "Started File 50\n",
      "Finished File 50\n",
      "Started File 51\n",
      "Finished File 51\n",
      "Started File 52\n",
      "Finished File 52\n",
      "Started File 53\n",
      "Finished File 53\n",
      "Started File 54\n",
      "Finished File 54\n",
      "Started File 55\n",
      "Finished File 55\n",
      "Started File 56\n",
      "Finished File 56\n",
      "Started File 57\n",
      "Finished File 57\n",
      "Started File 58\n",
      "Finished File 58\n",
      "Started File 59\n",
      "Finished File 59\n",
      "Started File 60\n",
      "Finished File 60\n",
      "Started File 61\n",
      "Finished File 61\n",
      "Started File 62\n",
      "Finished File 62\n",
      "Started File 63\n",
      "Finished File 63\n",
      "Started File 64\n",
      "Finished File 64\n",
      "Started File 65\n",
      "Finished File 65\n",
      "Started File 66\n",
      "Finished File 66\n",
      "Started File 67\n",
      "Finished File 67\n",
      "Started File 68\n",
      "Finished File 68\n",
      "Started File 69\n",
      "Finished File 69\n",
      "Started File 70\n",
      "Finished File 70\n",
      "Started File 71\n",
      "Finished File 71\n",
      "Started File 72\n",
      "Finished File 72\n",
      "Started File 73\n",
      "Finished File 73\n",
      "Started File 74\n",
      "Finished File 74\n",
      "Started File 75\n",
      "Finished File 75\n",
      "Started File 76\n",
      "Finished File 76\n",
      "Started File 77\n",
      "Finished File 77\n",
      "Started File 78\n",
      "Finished File 78\n",
      "Started File 79\n",
      "Finished File 79\n",
      "Started File 80\n",
      "Finished File 80\n",
      "Started File 81\n",
      "Finished File 81\n",
      "Started File 82\n",
      "Finished File 82\n",
      "Started File 83\n",
      "Finished File 83\n",
      "Started File 84\n",
      "Finished File 84\n",
      "Started File 85\n",
      "Finished File 85\n",
      "Started File 86\n",
      "Finished File 86\n",
      "Started File 87\n",
      "Finished File 87\n",
      "Started File 88\n",
      "Finished File 88\n",
      "Started File 89\n",
      "Finished File 89\n",
      "Started File 90\n",
      "Finished File 90\n",
      "Started File 91\n",
      "Finished File 91\n",
      "Started File 92\n",
      "Finished File 92\n",
      "Started File 93\n",
      "Finished File 93\n",
      "Started File 94\n",
      "Finished File 94\n",
      "Started File 95\n",
      "Finished File 95\n",
      "Started File 96\n",
      "Finished File 96\n",
      "Started File 97\n",
      "Finished File 97\n",
      "Started File 98\n",
      "Finished File 98\n",
      "Started File 99\n",
      "Finished File 99\n",
      "Started File 100\n",
      "Finished File 100\n",
      "Started File 101\n",
      "Finished File 101\n",
      "Started File 102\n",
      "Finished File 102\n",
      "Started File 103\n",
      "Finished File 103\n",
      "Started File 104\n",
      "Finished File 104\n",
      "Started File 105\n",
      "Finished File 105\n",
      "Started File 106\n",
      "Finished File 106\n",
      "Started File 107\n",
      "Finished File 107\n",
      "Started File 108\n",
      "Finished File 108\n",
      "Started File 109\n",
      "Finished File 109\n",
      "Started File 110\n",
      "Finished File 110\n",
      "Started File 111\n",
      "Finished File 111\n",
      "Started File 112\n",
      "Finished File 112\n",
      "Started File 113\n",
      "Finished File 113\n",
      "Started File 114\n",
      "Finished File 114\n",
      "Started File 115\n",
      "Finished File 115\n",
      "Started File 116\n",
      "Finished File 116\n",
      "Started File 117\n",
      "Finished File 117\n",
      "Started File 118\n",
      "Finished File 118\n",
      "Started File 119\n",
      "Finished File 119\n",
      "Started File 120\n",
      "Finished File 120\n",
      "Started File 121\n",
      "Finished File 121\n",
      "Started File 122\n",
      "Finished File 122\n",
      "Started File 123\n",
      "Finished File 123\n",
      "Started File 124\n",
      "Finished File 124\n",
      "Started File 125\n",
      "Finished File 125\n",
      "Started File 126\n",
      "Finished File 126\n",
      "Started File 127\n",
      "Finished File 127\n",
      "Started File 128\n",
      "Finished File 128\n",
      "Started File 129\n",
      "Finished File 129\n",
      "Started File 130\n",
      "Finished File 130\n",
      "Started File 131\n",
      "Finished File 131\n",
      "Started File 132\n",
      "Finished File 132\n",
      "Started File 133\n",
      "Finished File 133\n",
      "Started File 134\n",
      "Finished File 134\n",
      "Started File 135\n",
      "Finished File 135\n",
      "Started File 136\n",
      "Finished File 136\n",
      "Started File 137\n",
      "Finished File 137\n",
      "Started File 138\n",
      "Finished File 138\n",
      "Started File 139\n",
      "Finished File 139\n",
      "Started File 140\n",
      "Finished File 140\n",
      "Started File 141\n",
      "Finished File 141\n",
      "Started File 142\n",
      "Finished File 142\n",
      "Started File 143\n",
      "Finished File 143\n",
      "Started File 144\n",
      "Finished File 144\n",
      "Started File 145\n",
      "Finished File 145\n",
      "Started File 146\n",
      "Finished File 146\n",
      "Started File 147\n",
      "Finished File 147\n",
      "Started File 148\n",
      "Finished File 148\n",
      "Started File 149\n",
      "Finished File 149\n",
      "Started File 150\n",
      "Finished File 150\n",
      "Started File 151\n",
      "Finished File 151\n",
      "Started File 152\n",
      "Finished File 152\n",
      "Started File 153\n",
      "Finished File 153\n",
      "Started File 154\n",
      "Finished File 154\n",
      "Started File 155\n",
      "Finished File 155\n",
      "Started File 156\n",
      "Finished File 156\n",
      "Started File 157\n",
      "Finished File 157\n",
      "Started File 158\n",
      "Finished File 158\n",
      "Started File 159\n",
      "Finished File 159\n",
      "Started File 160\n",
      "Finished File 160\n",
      "Started File 161\n",
      "Finished File 161\n",
      "Started File 162\n",
      "Finished File 162\n",
      "Started File 163\n",
      "Finished File 163\n",
      "Started File 164\n",
      "Finished File 164\n",
      "Started File 165\n",
      "Finished File 165\n",
      "Started File 166\n",
      "Finished File 166\n",
      "Started File 167\n",
      "Finished File 167\n",
      "Started File 168\n",
      "Finished File 168\n",
      "Started File 169\n",
      "Finished File 169\n",
      "Started File 170\n",
      "Finished File 170\n",
      "Started File 171\n",
      "Finished File 171\n",
      "Started File 172\n",
      "Finished File 172\n",
      "Started File 173\n",
      "Finished File 173\n",
      "Started File 174\n",
      "Finished File 174\n",
      "Started File 175\n",
      "Finished File 175\n",
      "Started File 176\n",
      "Finished File 176\n",
      "Started File 177\n",
      "Finished File 177\n",
      "Started File 178\n",
      "Finished File 178\n",
      "Started File 179\n",
      "Finished File 179\n",
      "Started File 180\n",
      "Finished File 180\n",
      "Started File 181\n",
      "Finished File 181\n",
      "Started File 182\n",
      "Finished File 182\n",
      "Started File 183\n",
      "Finished File 183\n",
      "Started File 184\n",
      "Finished File 184\n",
      "Started File 185\n",
      "Finished File 185\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "resultsC = pd.DataFrame()\n",
    "for wave_file in glob.glob(fileGlob):\n",
    "    print(\"Started File \" + str(count))\n",
    "    patient_id = wave_file[-7:-4]\n",
    "    resultsC = resultsC.append(COVAREP(patient_id))\n",
    "    \n",
    "    print(\"Finished File \" + str(count))\n",
    "    count = count + 1\n",
    "\n",
    "dataDavid = pd.merge(dataDavid, resultsC, on ='patient_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74e02d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDuration= pd.read_csv('C:/Users/admul/Desktop/School/Thesis/DAICWOZ Data/Altered Audio/DurationData.csv',\n",
    "                             sep=',', na_values = 'Null')\n",
    "\n",
    "dataDuration.columns =['patient_id', 'response_dur_mean', 'response_dur_sd', 'overlap_mean', 'overlap_sd',\n",
    "                                       'response_no_overlap_mean', 'response_no_overlap_sd']\n",
    "\n",
    "dataDuration = dataDuration.dropna(thresh=4)\n",
    "dataDuration = dataDuration[dataDuration.patient_id != 304]\n",
    "\n",
    "dataDavid = pd.merge(dataDavid, dataDuration, on ='patient_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f8f3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9a6a0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDavid.to_csv('C:/Users/admul/Desktop/School/Thesis/DAICWOZ Data/Altered Audio/Ellie Removed/model_prepped_data_Ellie_Lit_Removed_082722_15b.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c15ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDavid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1518c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "822995e5",
   "metadata": {},
   "source": [
    "If you want to compare the magnitude of your spectra, you should use scaling='spectrum'. If you compare integrals over a bandwidth, you should use scaling='density'.\n",
    "\n",
    "https://github.com/scipy/scipy/issues/8651\n",
    "\n",
    "https://stackoverflow.com/questions/71575836/proper-use-of-window-parameter-for-welch-power-spectral-density-scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f0a87c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ee7c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e0311c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
